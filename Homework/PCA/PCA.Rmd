---
title: "PCA: Principal Component Analysis"
author: "Jin Seo Jo"
date: "30/09/2020"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(fig.path = "README_figs/README-")
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE}
library(tidyverse)
library(tidymodels)
library(tidytext)
library(janitor)
```

Note: `tidymodels` package is acollection of R packages that are made for doing machine learning modelling.  

The simplest version of the workflow is  
1. Define a **recipe** for your data preparation. This helps formalize the steps in your analysis workflow.  
2. **Prepare** your data for analysis by running the recipe on it.  
3. **Run** your analysis and tidy up the results.  

## Load the data
The data that we will use is a collection of cocktail recipes. 
```{r}
boston_cocktails <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-26/boston_cocktails.csv")

nrow(boston_cocktails)
ls(boston_cocktails)
```

It contains 3643 observations and 6 variables.

## Clean up the data
```{r}
cocktails_parsed <- boston_cocktails %>%
  mutate(
    ingredient = str_to_lower(ingredient),
    ingredient = str_replace_all(ingredient, "-", " "),
    ingredient = str_remove(ingredient, " liqueur$"),
    ingredient = str_remove(ingredient, " (if desired)$"),
    ingredient = case_when(
      str_detect(ingredient, "bitters") ~ "bitters",
      str_detect(ingredient, "lemon") ~ "lemon juice",
      str_detect(ingredient, "lime") ~ "lime juice",
      str_detect(ingredient, "grapefruit") ~ "grapefruit juice",
      str_detect(ingredient, "orange") ~ "orange juice",
      TRUE ~ ingredient
    ),
    measure = case_when(
      str_detect(ingredient, "bitters") ~ str_replace(measure, "oz$", "dash"),
      TRUE ~ measure
    ),
    measure = str_replace(measure, " ?1/2", ".5"),
    measure = str_replace(measure, " ?3/4", ".75"),
    measure = str_replace(measure, " ?1/4", ".25"),
    measure_number = parse_number(measure),
    measure_number = if_else(str_detect(measure, "dash$"),
      measure_number / 50,
      measure_number
    )
  ) %>%
  add_count(ingredient) %>%
  filter(n > 15) %>%
  select(-n) %>%
  distinct(row_id, ingredient, .keep_all = TRUE) %>% 
  na.omit
```

There are some warnings. They are not a sign that something is wrong, just that something happended that we should know about. 

We may notice some weird characters in the strings. For example, 
```{r, eval=FALSE}
ingredient = str_remove(ingredient, " liqueur$")
```

Let's break it down. The`str_remove` function is a part of the `stringr` package (loaded by `package(tidyverse)`). It removes something from a string. The syntax is
```{r, eval=FALSE}
str_remove(string, pattern)
```

**String**:  
In our case, `string` is each entry of the `ingredient` column. 

**Pattern**:  
It is a _regualr expression pattern_, which is a way to cycle through text to find what you need.  
Regualr expressions (or regex) is a powerful little language that let's us find quite complex patterns from text.    
To do that, it has a pile of special characters that mean special things. In this case, the `$` means "end of string".  
So `pattern = "liqueur$"` tries to find the substring 'liqueur' that is at the end of the text being examined. 

Examples:
```{r}
# Case 1:
str_remove("this liqueur is coconut liqueur", " liqueur$")
# Case 2:
str_remove("this liqueur is coconut liqueur", " liqueur")
# Case 3:
str_remove("this liqueur is coconut", " liqueur$")
```

In the third case, it did not find the substring 'liqueur' at the end of the search string, so it returned the string untouched. This is what we want!

```{r}
# Case 1:
str_replace("1/2 oz of tequila", " ?1/2", ".5")
# Case 2:
str_replace("1/3 oz of tequila", " ?1/2", ".5")
# Case 3:
str_replace("1/2 oz of 1/2 tequila", " ?1/2", ".5")
```

Now check the format of the data
```{r}
# View(cocktails_parsed) or
cocktails_parsed
```

This is what is called **long** format. Each row corresponds to one measurement of one thing.  
But to do PCA we need out data in **wide** format.  
This is when each row tells us multiple things about an observation, such as the whole vector $x_i^T$.  
So we will use `pivot_wider`.

```{r}
cocktails_df <- cocktails_parsed %>%
  select(-ingredient_number, -row_id, -measure) %>%
  pivot_wider(id_cols = name, 
    names_from = ingredient, 
    values_from = measure_number, 
    values_fill = 0) %>%
  janitor::clean_names() %>%
  na.omit()
```

First thing this does is delete the rows we don't need. It then pivots the data into a wide format.  

- The rows will come from the `id_col` arguement, so each row will be a specific cocktail
- The column names come from the `names_from` argument, and are hence read from the column `ingredient`. This means that each ingredient will get it's own column
- The values that go in that column come from the corresponding `measure_number` column, or are set to zero (`values_fill`) if that ingredient isn't used in that cocktail

The `clean_names` command from the `janitor` package is then called to make sure that everthing is written consistently.  
Finally, any `NA` values are thrown away.

Then our new data look like this
```{r}
cocktails_df
```

We still need to get our data ready for PCA.  
What we are going to do now is describe, for our clean data, what we are going to do before we do the PCA.  

To do this, we need to define a _recipe_, which is done using the `recipe` package, which is part of `tidymodels`. 

There are two steps here:  
1. We write the recipe `recipe()`  
2. We get all of the ingredients in place for out analysis `prep()`

```{r}
# Step 1
pca_rec <- recipe(~., data = cocktails_df) %>% 
  # Step 2
  update_role(name, new_role = "id") %>%
  # Step 3.1
  step_normalize(all_predictors()) %>%
  # Step 3.2
  step_pca(all_predictors())

pca_prep <- prep(pca_rec)

pca_prep
```

Interpret the codes:  
- Step 1: ~. means "I am predicting nothing (nothing on the left of ~), but my covariates are everything in my data (the . on the right of ~)".  
- Step 2:  We don't want to use the cocktail name in our PCA, so we give it the "role" of an "id" or identification column. This will be useful for printing etc.  
- Step 3.1: This normalize the given data. This makes all predictor columns (everything that isn't an `id` column in this case) have mean zero and standard deviation 1. We need this to make PCA work nicely and avoid bad scaling issues.  
- Step 3.2: This performs the PCA

`prep` function:  
- It goes through the recipe in order and does all of the things it says.  
- First, it makes sure `name` is listed as an id-column.  
- Then it scales and centres the other columns.  
- And then it does the PCA on the non-id columns.

It's still not in a nice form where we can use it, so we can do one final thing. We can `tidy` the output.  
`tidy` is a function (or one function for each type of analysis) that is bought to us by the `broom` package.  
It tries to wrangle the output into a neat format. 
```{r}
# Tidy the Step 3.1
# 2 means "tidy the second 'step_' of our recipe" (this is the PCA step)
tidied_pca <- tidy(pca_prep, 2)
```

```{r}
# Tidy the Step 3.2
# 1 indicates normalization step
tidy(pca_prep, 1)
```

`tidied_pca` is living in long format, so it's slightly easier if we pivot wider:
```{r}
tidied_pca %>% select(-id) %>%
  pivot_wider(names_from = component, values_from = value)
```

This is a 40x40 matrix (if we don't include the `name` column).  
Remember that a score vector has the length of the number of cocktails ($n$), while the loading vector would have the dimension of the number of ingredients ($p$).
```{r}
length(unique(cocktails_parsed$name))
length(unique(cocktails_parsed$ingredient))
```

This means that these are the PCA loadings, which is what we want.

We can now do some plotting. 

## visualizing results
```{r}
tidied_pca %>%
  filter(component %in% paste0("PC", 1:5)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(value, terms, fill = terms)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~component, nrow = 1) +
  labs(y = NULL)
```

From PC1, we can see that `powdered_sugar` and `simple_syrup` make the biggest difference.  

It would be nice to just plot the most important part of the each PC. 
```{r}
tidied_pca %>%
  filter(component %in% paste0("PC", 1:4)) %>%
  group_by(component) %>%
  top_n(8, abs(value)) %>%
  ungroup() %>%
  mutate(terms = reorder_within(terms, abs(value), component)) %>%
  ggplot(aes(abs(value), terms, fill = value > 0)) +
  geom_col() +
  facet_wrap(~component, scales = "free_y") +
  scale_y_reordered() +
  labs(
    x = "Absolute value of contribution",
    y = NULL, fill = "Positive?"
  )
```
